{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "34197a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import torch.optim as optim\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7a2dace2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78c79045",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ffb9d13c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "979af2f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU 0: NVIDIA GeForce RTX 4070 Ti\n",
      "Total Memory: 12.0GB\n",
      "Allocated Memory: 0.0GB\n",
      "Free Memory: 12.0GB\n",
      "Using GPU 0 with 12.0GB free VRAM\n"
     ]
    }
   ],
   "source": [
    "# Check available CUDA devices and memory\n",
    "if torch.cuda.is_available():\n",
    "    num_devices = torch.cuda.device_count()\n",
    "    for i in range(num_devices):\n",
    "        device = torch.cuda.device(i)\n",
    "        total_mem = torch.cuda.get_device_properties(i).total_memory / 1024**3  # Convert to GB\n",
    "        allocated_mem = torch.cuda.memory_allocated(i) / 1024**3  # Convert to GB\n",
    "        free_mem = total_mem - allocated_mem\n",
    "        \n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        print(f\"Total Memory: {total_mem:.1f}GB\")\n",
    "        print(f\"Allocated Memory: {allocated_mem:.1f}GB\")\n",
    "        print(f\"Free Memory: {free_mem:.1f}GB\")\n",
    "        \n",
    "        if free_mem < 8:\n",
    "            print(f\"Warning: GPU {i} has less than 8GB of free VRAM!\")\n",
    "        else:\n",
    "            print(f\"Using GPU {i} with {free_mem:.1f}GB free VRAM\")\n",
    "            break \n",
    "    device = torch.device(f\"cuda:{i}\")\n",
    "else:\n",
    "    print(\"Warning: No CUDA devices available - running on CPU only\")\n",
    "    device = torch.device(\"cpu\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191bc2d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function and optimizer\n",
    "loss_fn = nn.MSELoss()  # mean square error\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.0001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b0f8eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class SolarDataset(Dataset):\n",
    "    def __init__(self, net_load, solar_gen=None, sequence_length=24):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            net_load (numpy array or list): Net load values over time.\n",
    "            weather (numpy array or list): Corresponding weather features.\n",
    "            solar_gen (numpy array or list, optional): Solar generation values for supervised learning.\n",
    "            sequence_length (int): Number of past time steps to include in each input sequence.\n",
    "        \"\"\"\n",
    "        self.net_load = torch.tensor(net_load, dtype=torch.float32).unsqueeze(-1)\n",
    "        #self.weather = torch.tensor(weather, dtype=torch.float32)\n",
    "        self.solar_gen = torch.tensor(solar_gen, dtype=torch.float32) if solar_gen is not None else None\n",
    "        self.sequence_length = sequence_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.net_load) - self.sequence_length  # Total number of samples\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        net_seq = self.net_load[idx:idx+self.sequence_length]\n",
    "        #weather_seq = self.weather[idx:idx+self.sequence_length]\n",
    "\n",
    "        if self.solar_gen is not None:\n",
    "            target = self.solar_gen[idx+self.sequence_length]  # Next time step's solar generation\n",
    "            return net_seq, target\n",
    "        else:\n",
    "            return net_seq  # Used for inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "053b731b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.read_csv(\"./model_input_data/2010-2012.csv\")\n",
    "df_test = pd.read_csv(\"./model_input_data/2012-2013.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51caad2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer       date  Time     GC             datetime   GG   CL     NL  \\\n",
      "0         6  01-Jul-10  0:00  0.036  2010-07-01 00:00:00  0.0  0.0  0.036   \n",
      "1         6  01-Jul-10  0:30  0.044  2010-07-01 00:30:00  0.0  0.0  0.044   \n",
      "2         6  01-Jul-10  1:00  0.041  2010-07-01 01:00:00  0.0  0.0  0.041   \n",
      "3         6  01-Jul-10  1:30  0.047  2010-07-01 01:30:00  0.0  0.0  0.047   \n",
      "4         6  01-Jul-10  2:00  0.046  2010-07-01 02:00:00  0.0  0.0  0.046   \n",
      "\n",
      "   Row Quality_x  Row Quality_y  Row Quality  \n",
      "0            NaN            NaN          NaN  \n",
      "1            NaN            NaN          NaN  \n",
      "2            NaN            NaN          NaN  \n",
      "3            NaN            NaN          NaN  \n",
      "4            NaN            NaN          NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f870fa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Customer       date  Row Quality_x  Time     GC             datetime  \\\n",
      "0       233  1/07/2012            NaN  0:00  0.040  2012-07-01 00:00:00   \n",
      "1       233  1/07/2012            NaN  0:30  0.040  2012-07-01 00:30:00   \n",
      "2       233  1/07/2012            NaN  1:00  0.034  2012-07-01 01:00:00   \n",
      "3       233  1/07/2012            NaN  1:30  0.039  2012-07-01 01:30:00   \n",
      "4       233  1/07/2012            NaN  2:00  0.039  2012-07-01 02:00:00   \n",
      "\n",
      "   Row Quality_y     GG     NL  Row Quality  CL  \n",
      "0            NaN  0.006  0.034          NaN NaN  \n",
      "1            NaN  0.000  0.040          NaN NaN  \n",
      "2            NaN  0.006  0.028          NaN NaN  \n",
      "3            NaN  0.000  0.039          NaN NaN  \n",
      "4            NaN  0.000  0.039          NaN NaN  \n"
     ]
    }
   ],
   "source": [
    "print(df_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "97e59e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selecting relevant columns\n",
    "net_load_train = df_train[\"NL\"].values\n",
    "#weather_train = train_df[[\"Temperature\", \"Solar Irradiance\", \"Humidity\"]].values  # Adjust based on dataset\n",
    "solar_gen_train = df_train[\"GG\"].values if \"GG\" in df_train else None\n",
    "\n",
    "net_load_test = df_test[\"NL\"].values\n",
    "#weather_test = test_df[[\"Temperature\", \"Solar Irradiance\", \"Humidity\"]].values\n",
    "solar_gen_test = df_test[\"GG\"].values if \"GG\" in df_test else None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d919e2b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to PyTorch Dataset\n",
    "#train_dataset = SolarDataset(net_load_train, weather_train, solar_gen_train, sequence_length=24)\n",
    "#test_dataset = SolarDataset(net_load_test, weather_test, solar_gen_test, sequence_length=24)\n",
    "# Convert to PyTorch Dataset\n",
    "training_data = SolarDataset(net_load_train, solar_gen_train, sequence_length=24)\n",
    "test_data = SolarDataset(net_load_test, solar_gen_test, sequence_length=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ff8628ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total samples available: 10518216\n"
     ]
    }
   ],
   "source": [
    "# Check dataset length\n",
    "print(f\"Total samples available: {len(training_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9664a31d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net Load Sequence Shape: torch.Size([24, 1])\n",
      "Target (Solar Generation) Value: tensor(0.6250)\n"
     ]
    }
   ],
   "source": [
    "net_seq, target = training_data[0]  # Get the first sample\n",
    "\n",
    "print(\"Net Load Sequence Shape:\", net_seq.shape)\n",
    "#print(\"Weather Sequence Shape:\", weather_seq.shape)\n",
    "print(\"Target (Solar Generation) Value:\", target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b1abd712",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "train_dataloader = DataLoader(training_data, batch_size=64, shuffle=True)\n",
    "#test_dataloader = DataLoader(test_data, batch_size=64, shuffle=True/False)\n",
    "test_dataloader = DataLoader(test_data, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bba6843c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch Net Load Shape: torch.Size([64, 24, 1])\n",
      "Batch Target Shape: torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "for net_seq, target in train_dataloader:\n",
    "    print(\"Batch Net Load Shape:\", net_seq.shape)\n",
    "    #print(\"Batch Weather Shape:\", weather_seq.shape)\n",
    "    print(\"Batch Target Shape:\", target.shape)\n",
    "    break  # Only print first batch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9dfb8fd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "3f565ddd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Loss: 0.009413103695231744\n",
      "Epoch 2, Loss: 0.008707379919137758\n",
      "Epoch 3, Loss: 0.008475266136201073\n",
      "Epoch 4, Loss: 0.008334303024419659\n",
      "Epoch 5, Loss: 0.00823465331809194\n",
      "Epoch 6, Loss: 0.008145611358767296\n",
      "Epoch 7, Loss: 0.008078296554285788\n",
      "Epoch 8, Loss: 0.008024703321467527\n",
      "Epoch 9, Loss: 0.007965441006583916\n",
      "Epoch 10, Loss: 0.00791951701160443\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Initialize model\n",
    "#input_size = weather_train.shape[1]  # Number of weather features\n",
    "input_size = 1  # Assuming net load is a single feature\n",
    "model = LSTM(input_size, hidden_size=64, num_layers=2, output_size=1).to(device)\n",
    "\n",
    "# Define loss function and optimizer\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# Training Loop\n",
    "for epoch in range(10):  # Set desired number of epochs\n",
    "    model.train()\n",
    "    epoch_loss = 0\n",
    "\n",
    "    for net_seq, target in train_dataloader:\n",
    "        net_seq, target = net_seq.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        #output = model(weather_seq)  # Model learns from weather data\n",
    "        output = model(net_seq)\n",
    "\n",
    "        # Compute loss\n",
    "        loss = criterion(output.squeeze(), target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "    print(f\"Epoch {epoch+1}, Loss: {epoch_loss / len(train_dataloader)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73629443",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, csv_file, target_column):\n",
    "        self.data = pd.read_csv(csv_file)\n",
    "        self.target_column = target_column\n",
    "\n",
    "        # Normalize numerical features\n",
    "        self.scaler = MinMaxScaler()\n",
    "        self.data[self.data.select_dtypes(include=['float64', 'int64']).columns] = self.scaler.fit_transform(\n",
    "            self.data.select_dtypes(include=['float64', 'int64']).values)\n",
    "\n",
    "        # One-hot encode categorical features\n",
    "        self.encoder = OneHotEncoder(sparse=False)\n",
    "        categorical_cols = self.data.select_dtypes(include=['object']).columns\n",
    "        encoded_categorical_data = self.encoder.fit_transform(self.data[categorical_cols])\n",
    "        encoded_categorical_df = pd.DataFrame(encoded_categorical_data, columns=self.encoder.get_feature_names_out(categorical_cols))\n",
    "        \n",
    "        # Combine normalized numerical data with one-hot encoded categorical data\n",
    "        self.data = pd.concat([self.data.drop(columns=categorical_cols), encoded_categorical_df], axis=1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.data.iloc[idx]\n",
    "        target = row[self.target_column]\n",
    "        features = row.drop(self.target_column).values.astype(float)\n",
    "        return torch.tensor(features, dtype=torch.float32), torch.tensor(target, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b639f525",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LSTM(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, num_layers, output_size):\n",
    "        super(LSTM, self).__init__()\n",
    "        self.lstm = nn.LSTM(input_size, hidden_size, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_size, output_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out, _ = self.lstm(x)\n",
    "        out = self.fc(out[:, -1, :])\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f16edf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "class Model(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size, output_size):\n",
    "        super(Model, self).__init__()\n",
    "        self.input_size = input_size\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.lstm = nn.LSTMCell(self.input_size, self.hidden_size)\n",
    "        self.linear = nn.Linear(self.hidden_size, self.output_size)\n",
    "    def forward(self, input, future=0, y=None):\n",
    "        outputs = []\n",
    "        # reset the state of LSTM\n",
    "        # the state is kept till the end of the sequence\n",
    "        h_t = torch.zeros(input.size(0), self.hidden_size, dtype=torch.float32)\n",
    "        c_t = torch.zeros(input.size(0), self.hidden_size, dtype=torch.float32)\n",
    "        for i, input_t in enumerate(input.chunk(input.size(1), dim=1)):\n",
    "            h_t, c_t = self.lstm(input_t, (h_t, c_t))\n",
    "            output = self.linear(h_t)\n",
    "            outputs += [output]\n",
    "        for i in range(future):\n",
    "            if y is not None and random.random() > 0.5:\n",
    "                output = y[:, [i]]  # teacher forcing\n",
    "            h_t, c_t = self.lstm(output, (h_t, c_t))\n",
    "            output = self.linear(h_t)\n",
    "            outputs += [output]\n",
    "        outputs = torch.stack(outputs, 1).squeeze(2)\n",
    "        return outputs"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
